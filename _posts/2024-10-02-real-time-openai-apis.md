---
layout: post
title:  "Real time multi modal api capabilities announced by OpenAI"
date:   2024-10-02 00:00:00 +0000
categories: multi-modal openai llm real time
---
Recently, [OpenAI has released](https://openai.com/index/introducing-the-realtime-api/){:target="_blank"} a new set of APIs in beta release which enable to get responses in text and audio in real time using web sockets. This is an interesting development along with third party integration services to popular communication platforms like Twilio which have also been shared in the announcement towards the end.

Documentation guide to get you started can be found [here](https://platform.openai.com/docs/guides/realtime){:target="_blank"} with a [sample project code base in github](https://github.com/openai/openai-realtime-api-beta){:target="_blank"}.

Third party integrations with the realtime api can be found for below three vendors:
1. [LiveKit](https://docs.livekit.io/agents/openai/overview/){:target="_blank"}
2. [Agora](https://www.agora.io/en/products/agora-openai-conversational-ai-sdk/){:target="_blank"}
3. [Twilio](https://www.twilio.com/en-us/blog/twilio-openai-realtime-api-launch-integration){:target="_blank"}

Hope you build some interesting applications using it!
